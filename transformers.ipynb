{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "    - pytorch-cuda=11.8\n",
      "    - torchaudio\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    cuda-cudart-11.8.89        |                0         197 KB  nvidia\n",
      "    cuda-cupti-11.8.87         |                0        25.3 MB  nvidia\n",
      "    cuda-libraries-11.8.0      |                0           1 KB  nvidia\n",
      "    cuda-nvrtc-11.8.89         |                0        19.1 MB  nvidia\n",
      "    cuda-nvtx-11.8.86          |                0          57 KB  nvidia\n",
      "    cuda-runtime-11.8.0        |                0           1 KB  nvidia\n",
      "    ffmpeg-4.3                 |       hf484d3e_0         9.9 MB  pytorch\n",
      "    gnutls-3.6.15              |       he1e5248_0         1.0 MB\n",
      "    lame-3.100                 |       h7b6447c_0         323 KB\n",
      "    libcublas-11.11.3.6        |                0       364.0 MB  nvidia\n",
      "    libcufft-10.9.0.58         |                0       142.8 MB  nvidia\n",
      "    libcufile-1.6.0.25         |                0         763 KB  nvidia\n",
      "    libcurand-10.3.2.56        |                0        51.7 MB  nvidia\n",
      "    libcusolver-11.4.1.48      |                0        96.5 MB  nvidia\n",
      "    libcusparse-11.7.5.86      |                0       176.3 MB  nvidia\n",
      "    libiconv-1.16              |       h7f8727e_2         736 KB\n",
      "    libnpp-11.8.0.86           |                0       147.8 MB  nvidia\n",
      "    libnvjpeg-11.9.0.86        |                0         2.4 MB  nvidia\n",
      "    libtasn1-4.19.0            |       h5eee18b_0          63 KB\n",
      "    nettle-3.7.3               |       hbbd107a_1         809 KB\n",
      "    openh264-2.1.1             |       h4ff587b_0         711 KB\n",
      "    pytorch-2.0.0              |py3.9_cuda11.8_cudnn8.7.0_0        1.41 GB  pytorch\n",
      "    pytorch-cuda-11.8          |       h7e8668a_3           7 KB  pytorch\n",
      "    pytorch-mutex-1.0          |             cuda           3 KB  pytorch\n",
      "    torchaudio-2.0.0           |       py39_cu118         7.5 MB  pytorch\n",
      "    torchtriton-2.0.0          |             py39        62.5 MB  pytorch\n",
      "    torchvision-0.15.0         |       py39_cu118         7.8 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        2.50 GB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cuda-cudart        nvidia/linux-64::cuda-cudart-11.8.89-0 None\n",
      "  cuda-cupti         nvidia/linux-64::cuda-cupti-11.8.87-0 None\n",
      "  cuda-libraries     nvidia/linux-64::cuda-libraries-11.8.0-0 None\n",
      "  cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-11.8.89-0 None\n",
      "  cuda-nvtx          nvidia/linux-64::cuda-nvtx-11.8.86-0 None\n",
      "  cuda-runtime       nvidia/linux-64::cuda-runtime-11.8.0-0 None\n",
      "  ffmpeg             pytorch/linux-64::ffmpeg-4.3-hf484d3e_0 None\n",
      "  gnutls             pkgs/main/linux-64::gnutls-3.6.15-he1e5248_0 None\n",
      "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0 None\n",
      "  libcublas          nvidia/linux-64::libcublas-11.11.3.6-0 None\n",
      "  libcufft           nvidia/linux-64::libcufft-10.9.0.58-0 None\n",
      "  libcufile          nvidia/linux-64::libcufile-1.6.0.25-0 None\n",
      "  libcurand          nvidia/linux-64::libcurand-10.3.2.56-0 None\n",
      "  libcusolver        nvidia/linux-64::libcusolver-11.4.1.48-0 None\n",
      "  libcusparse        nvidia/linux-64::libcusparse-11.7.5.86-0 None\n",
      "  libiconv           pkgs/main/linux-64::libiconv-1.16-h7f8727e_2 None\n",
      "  libnpp             nvidia/linux-64::libnpp-11.8.0.86-0 None\n",
      "  libnvjpeg          nvidia/linux-64::libnvjpeg-11.9.0.86-0 None\n",
      "  libtasn1           pkgs/main/linux-64::libtasn1-4.19.0-h5eee18b_0 None\n",
      "  nettle             pkgs/main/linux-64::nettle-3.7.3-hbbd107a_1 None\n",
      "  openh264           pkgs/main/linux-64::openh264-2.1.1-h4ff587b_0 None\n",
      "  pytorch-cuda       pytorch/linux-64::pytorch-cuda-11.8-h7e8668a_3 None\n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda None\n",
      "  torchaudio         pytorch/linux-64::torchaudio-2.0.0-py39_cu118 None\n",
      "  torchtriton        pytorch/linux-64::torchtriton-2.0.0-py39 None\n",
      "  torchvision        pytorch/linux-64::torchvision-0.15.0-py39_cu118 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  pytorch            pkgs/main::pytorch-1.12.1-cpu_py39hb1~ --> pytorch::pytorch-2.0.0-py3.9_cuda11.8_cudnn8.7.0_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pytorch-mutex-1.0    | 3 KB      | ##################################### | 100% \n",
      "cuda-nvtx-11.8.86    | 57 KB     | ##################################### | 100% \n",
      "libcublas-11.11.3.6  | 364.0 MB  | ##################################### | 100% \n",
      "libcufile-1.6.0.25   | 763 KB    | ##################################### | 100% \n",
      "nettle-3.7.3         | 809 KB    | ##################################### | 100% \n",
      "cuda-runtime-11.8.0  | 1 KB      | ##################################### | 100% \n",
      "cuda-cudart-11.8.89  | 197 KB    | ##################################### | 100% \n",
      "torchaudio-2.0.0     | 7.5 MB    | ##################################### | 100% \n",
      "libnvjpeg-11.9.0.86  | 2.4 MB    | ##################################### | 100% \n",
      "libtasn1-4.19.0      | 63 KB     | ##################################### | 100% \n",
      "gnutls-3.6.15        | 1.0 MB    | ##################################### | 100% \n",
      "lame-3.100           | 323 KB    | ##################################### | 100% \n",
      "cuda-nvrtc-11.8.89   | 19.1 MB   | ##################################### | 100% \n",
      "cuda-cupti-11.8.87   | 25.3 MB   | ##################################### | 100% \n",
      "libcurand-10.3.2.56  | 51.7 MB   | ##################################### | 100% \n",
      "openh264-2.1.1       | 711 KB    | ##################################### | 100% \n",
      "ffmpeg-4.3           | 9.9 MB    | ##################################### | 100% \n",
      "pytorch-2.0.0        | 1.41 GB   | ##################################### | 100% \n",
      "torchtriton-2.0.0    | 62.5 MB   | ##################################### | 100% \n",
      "torchvision-0.15.0   | 7.8 MB    | ##################################### | 100% \n",
      "libcufft-10.9.0.58   | 142.8 MB  | ##################################### | 100% \n",
      "libcusparse-11.7.5.8 | 176.3 MB  | ##################################### | 100% \n",
      "libcusolver-11.4.1.4 | 96.5 MB   | ##################################### | 100% \n",
      "pytorch-cuda-11.8    | 7 KB      | ##################################### | 100% \n",
      "libnpp-11.8.0.86     | 147.8 MB  | ##################################### | 100% \n",
      "cuda-libraries-11.8. | 1 KB      | ##################################### | 100% \n",
      "libiconv-1.16        | 736 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c huggingface transformers datasets tokenizers evaluate huggingface_hub -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://dl.yarnpkg.com/debian stable InRelease\n",
      "Hit:2 http://deb.debian.org/debian bullseye InRelease\n",
      "Hit:3 http://deb.debian.org/debian-security bullseye-security InRelease\n",
      "Hit:4 http://deb.debian.org/debian bullseye-updates InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libssl-dev is already the newest version (1.1.1n-0+deb11u4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install libssl-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - tokenizers\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  tokenizers         huggingface::tokenizers-0.13.0.dev0-p~ --> pkgs/main::tokenizers-0.11.4-py39h3dcd8bd_1 None\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!conda update tokenizers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer, TextClassificationPipeline\n",
    "from datasets import Dataset, ClassLabel, Features, Value\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ultimo choro se 2018 que delicia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pero es una realidad para muchas mujeres en Ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MALDITA SEAS COMUNA DE √ëU√ëOA https://t.co/yN4E...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Las tontas de  #PautaLibre con el tremendo üå∂üå∂ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user @user @user @user @user Devuelvete y and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12209</th>\n",
       "      <td>üîµüî¥ La ‚ÄúU‚Äù despidi√≥ a Dudamel con un empate.\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210</th>\n",
       "      <td>Armen la casa de puta, loco. C√≥manse a Rold√°n!...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12211</th>\n",
       "      <td>@user A m√≠ me penalizaron por merequetengue e ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12212</th>\n",
       "      <td>Me importa un pico si del Pino juega bien o ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12213</th>\n",
       "      <td>@user @user De inmediato supones que algo habr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12214 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                       ultimo choro se 2018 que delicia      0\n",
       "1      Pero es una realidad para muchas mujeres en Ve...      0\n",
       "2      MALDITA SEAS COMUNA DE √ëU√ëOA https://t.co/yN4E...      1\n",
       "3      Las tontas de  #PautaLibre con el tremendo üå∂üå∂ ...      1\n",
       "4      @user @user @user @user @user Devuelvete y and...      2\n",
       "...                                                  ...    ...\n",
       "12209  üîµüî¥ La ‚ÄúU‚Äù despidi√≥ a Dudamel con un empate.\\n\\...      0\n",
       "12210  Armen la casa de puta, loco. C√≥manse a Rold√°n!...      1\n",
       "12211  @user A m√≠ me penalizaron por merequetengue e ...      0\n",
       "12212  Me importa un pico si del Pino juega bien o ma...      1\n",
       "12213  @user @user De inmediato supones que algo habr...      0\n",
       "\n",
       "[12214 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/train/train.tsv\", sep=\"\\t\")\n",
    "data.columns = ['id', 'text', 'label']\n",
    "data.label = data.label.map({'normal':0, 'incivilidad': 1, 'odio':2})\n",
    "data = data[['text','label']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Features({\"text\": Value(\"string\"), \"label\": ClassLabel(num_classes=3, names=[0,1,2])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data, features=features).train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 8549\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3665\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e3b0ac1bd347d3ae2ed152ab85aaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8549 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b6fe57ecda4b6fbbe52a36a916e4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3665 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"normal\", 1: \"incivilidad\", 2:'odio'}\n",
    "\n",
    "label2id = {\"normal\": 0, \"incivilidad\": 1, 'odio':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\n",
    "    \"dccuchile/bert-base-spanish-wwm-cased\", num_labels=3, id2label=id2label, label2id=label2id\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "    output_dir=\"hater_model\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    num_train_epochs=2,\n",
    "\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    evaluation_strategy=\"epoch\",\n",
    "\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "\n",
    "    model=model,\n",
    "\n",
    "    args=training_args,\n",
    "\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    data_collator=data_collator,\n",
    "\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1070' max='1070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1070/1070 05:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.627700</td>\n",
       "      <td>0.450751</td>\n",
       "      <td>0.817462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.463539</td>\n",
       "      <td>0.828104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1070, training_loss=0.47175652156366366, metrics={'train_runtime': 330.744, 'train_samples_per_second': 51.696, 'train_steps_per_second': 3.235, 'total_flos': 845415272550492.0, 'train_loss': 0.47175652156366366, 'epoch': 2.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12db3b1ab936469c933450e3c6f83a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e6c7e8568142e883d50b3a14f78ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/fvillena/hater_model/commit/4133603f913b6f15b15dc92060374d30a39dfd7b', commit_message='Upload BertForSequenceClassification', commit_description='', oid='4133603f913b6f15b15dc92060374d30a39dfd7b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('hater_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/fvillena/hater_model/commit/d30f60be4a40f323843fc04b0caf89f72da84b48', commit_message='Upload tokenizer', commit_description='', oid='d30f60be4a40f323843fc04b0caf89f72da84b48', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub('hater_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pipe(dataset['test']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = np.array([[p[0]['score'],p[1]['score'],p[2]['score']] for p in predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04451904, 0.93562138, 0.01985958],\n",
       "       [0.92305464, 0.01400349, 0.06294189],\n",
       "       [0.01748722, 0.97010887, 0.01240395],\n",
       "       ...,\n",
       "       [0.08106995, 0.42701054, 0.49191946],\n",
       "       [0.00552912, 0.98276937, 0.0117015 ],\n",
       "       [0.00507274, 0.97307903, 0.02184826]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_labels = np.array(['normal','incivilidad','odio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal', 'incivilidad', 'odio'], dtype='<U11')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(test_set, predicted_set):\n",
    "    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n",
    "    medium_predicted = np.array(\n",
    "        [prediction[1] for prediction in predicted_set]\n",
    "    )\n",
    "    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n",
    "    inc_test = np.where(test_set == \"incivilidad\", 1.0, 0.0)\n",
    "    odio_test = np.where(test_set == \"odio\", 1.0, 0.0)\n",
    "    normal_test = np.where(test_set == \"normal\", 1.0, 0.0)\n",
    "    auc_high = roc_auc_score(inc_test, high_predicted)\n",
    "    auc_med = roc_auc_score(odio_test, medium_predicted)\n",
    "    auc_low = roc_auc_score(normal_test, low_predicted)\n",
    "    auc_w = (\n",
    "        normal_test.sum() * auc_low\n",
    "        + odio_test.sum() * auc_med\n",
    "        + inc_test.sum() * auc_high\n",
    "    ) / (normal_test.sum() + odio_test.sum() + inc_test.sum())\n",
    "    return auc_w\n",
    "\n",
    "\n",
    "def evaluate(predicted_probabilities, y_test, labels):\n",
    "    # Importante: al transformar los arreglos de probabilidad a clases,\n",
    "    # entregar el arreglo de clases aprendido por el clasificador.\n",
    "    # (que comunmente, es distinto a ['normal', 'odio', 'incivilidad'])\n",
    "    predicted_labels = [\n",
    "        labels[np.argmax(item)] for item in predicted_probabilities\n",
    "    ]\n",
    "\n",
    "    print(\"Matriz de confusi√≥n\")\n",
    "    print(\n",
    "        confusion_matrix(\n",
    "            y_test, predicted_labels, labels=[\"normal\", \"odio\", \"incivilidad\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"\\nReporte de clasificaci√≥n:\\n\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_test, predicted_labels, labels=[\"normal\", \"odio\", \"incivilidad\"]\n",
    "        )\n",
    "    )\n",
    "    # Reorder predicted probabilities array.\n",
    "    labels = labels.tolist()\n",
    "\n",
    "    predicted_probabilities = predicted_probabilities[\n",
    "        :,\n",
    "        [\n",
    "            labels.index(\"normal\"),\n",
    "            labels.index(\"odio\"),\n",
    "            labels.index(\"incivilidad\"),\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    auc = round(auc_score(y_test, predicted_probabilities), 3)\n",
    "    print(\"M√©tricas:\\n\\nAUC: \", auc, end=\"\\t\")\n",
    "    kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
    "    print(\"Kappa:\", kappa, end=\"\\t\")\n",
    "    accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"------------------------------------------------------\\n\")\n",
    "    return np.array([auc, kappa, accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04451904, 0.93562138, 0.01985958],\n",
       "       [0.92305464, 0.01400349, 0.06294189],\n",
       "       [0.01748722, 0.97010887, 0.01240395],\n",
       "       ...,\n",
       "       [0.08106995, 0.42701054, 0.49191946],\n",
       "       [0.00552912, 0.98276937, 0.0117015 ],\n",
       "       [0.00507274, 0.97307903, 0.02184826]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(list(map(lambda x: id2label[x],dataset['test']['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusi√≥n\n",
      "[[1068   84  168]\n",
      " [ 116  537  111]\n",
      " [ 125   65 1391]]\n",
      "\n",
      "Reporte de clasificaci√≥n:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.82      0.81      0.81      1320\n",
      "        odio       0.78      0.70      0.74       764\n",
      " incivilidad       0.83      0.88      0.86      1581\n",
      "\n",
      "    accuracy                           0.82      3665\n",
      "   macro avg       0.81      0.80      0.80      3665\n",
      "weighted avg       0.82      0.82      0.82      3665\n",
      "\n",
      "M√©tricas:\n",
      "\n",
      "AUC:  0.944\tKappa: 0.713\tAccuracy: 0.817\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate(predicted_probabilities, y_test, learned_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
